{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiscpl/PUC_MVP_MACHINE_LEARNING/blob/main/MVP_LUIS_CLAUDIO_SPRINT%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "189e79f1",
      "metadata": {
        "id": "189e79f1"
      },
      "source": [
        "# MVP Analytics – Machine Learning & Analytics\n",
        "\n",
        "**Nome:** Luis Cláudio da Paixão Lobato\n",
        "\n",
        "**Matrícula:** 4052025001146\n",
        "\n",
        "**Dataset:** [Heart Disease Cleveland UCI] (https://www.kaggle.com/datasets/cherngs/heart-disease-cleveland-uci/data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e660788c",
      "metadata": {
        "id": "e660788c"
      },
      "source": [
        "# 1. Definição do Problema\n",
        "\n",
        "\n",
        "O conjunto de dados Heart Disease Cleveland da UCI contém informações anônimas sobre pacientes, incluindo características clínicas e resultados de exames. Uma das colunas, chamada CONDITION, indica a presença ou ausência de doença cardíaca nesses pacientes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc5628ac",
      "metadata": {
        "id": "dc5628ac"
      },
      "source": [
        "### 1.1 Hipóteses sobre o problema e tipo de Machine Leaming a ser Empregado\n",
        "\n",
        "Hipótese a ser empregado no problema:\n",
        "\n",
        "- Dado um conjunto de características clínicas (indica presença ou não de doença cardíaca em pacientes anônimos), o objetivo é prever, com 95% de precisão, se um paciente tem ou não doença cardíaca.\n",
        "\n",
        "Tipo de Machine Leaming traçada:\n",
        "\n",
        "- Este é um problema de **classificação supervisionada**. Serão criadas algumas variáveis categóricas com labels para auxiliar na análise das informações e formação do modelo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c9ee312",
      "metadata": {
        "id": "8c9ee312"
      },
      "source": [
        "### 1.2 Restrições na Seleção dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4ea9668",
      "metadata": {
        "id": "e4ea9668"
      },
      "source": [
        "- As variáveis categóricas, não tinham os labels criado, foi necessário a criação desses labels para o entendimento das informações;\n",
        "- O total de registros de pacientes foram 297, que fere o mínimo de registros necessários para uma análise mais acurada do objeto em estudo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eab3b81",
      "metadata": {
        "id": "3eab3b81"
      },
      "source": [
        "### 1.3 Atributos do Dataset\n",
        "\n",
        "O dataset Heart Disease Cleveland da UCI contém 297 amostras, com 137 pacientes na condição de doença cardíaca e 160 pacientes sem ter essa doença. Abaixo seguem os atributos:\n",
        "\n",
        "- ***age***  (Idade em anos)\n",
        "\n",
        "- ***sex***  (Sexo  ***[1 = masculino; 0 = feminino]***)\n",
        "\n",
        "- ***cp***  (Tipo de dor toraxica  ***[0: angina típica (dor no peito tipica)\n",
        "1: angina atípica (dor no peito, não relacionada ao coração)\n",
        "2: dor não anginosa (espasmos, não relacionados ao coração)\n",
        "3: assintomático (dor toraxica, sem sinais da doença)]***)\n",
        "\n",
        "- ***trestbps***  (Pressão arterial em repouso em bps )\n",
        "\n",
        "- ***chol***  (Colesterol total em mg/dl)\n",
        "\n",
        "- ***fbs***  (Glicemia em jejum > 120 mg/dl ***[1 = verdadeiro; 0 = falso)***)\n",
        "\n",
        "- ***restecg***  (Resultados eletrocardiográficos em repouso  ***[ 0: normal\n",
        " 1: com anormalidade da onda ST-T (inversões da onda T e/ou supradesnivelamento ou infradesnivelamento do segmento ST > 0,05 mV)\n",
        " 2: apresentando hipertrofia ventricular esquerda provável ou definitiva pelos critérios de Estes]***)\n",
        "\n",
        "- ***thalach*** (Frequência cardíaca máxima atingida em bps)\n",
        "\n",
        "- ***exang***  (Dor induzida pelo exercício físico  ***[1 = sim; 0 = não]***)\n",
        "\n",
        "- ***oldpeak*** (Depressão induzida pelo exercicio físico (observa o stress do coração durante o exercicio físico))\n",
        "\n",
        "- ***slope***  (Inclinação do pico do segmento do exercício físico  ***[0: ascendente, 1: plano, 2: descida]***)\n",
        "\n",
        "- ***ca***  (Número de vasos principais comprometidos (0-3) coloridos por fluorosopia )\n",
        "\n",
        "- ***thal***  (Resultado do estresse de tálio  ***[0: normal, 1: defeito corrigido 2: defeito reversível]***)\n",
        "\n",
        "- ***condition***  (Condição Cardíaca  ***[0 = sem doença,  1 = doença]***)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "487f62d5",
      "metadata": {
        "id": "487f62d5"
      },
      "source": [
        "# 2. Análise de Dados - EDA\n",
        "\n",
        "Nesta etapa de Análise de Dados Exploratória (EDA) sobre o dataset Heart Disease Cleveland UCI, visamos entender a distribuição, as relações e as características das variáveis, o que é crucial para as etapas subsequentes de pré-processamento e modelagem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6021ad46",
      "metadata": {
        "id": "6021ad46"
      },
      "source": [
        "### 2.1 Importação das Bibliotecas Necessárias e Carga de Dados\n",
        "\n",
        "Esta seção consolida todas as importações de bibliotecas necessárias para a análise, visualização e pré-processamento dos dados, bem como o carregamento inicial do dataset Heart Disease Cleveland UCI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ed21c7",
      "metadata": {
        "id": "96ed21c7"
      },
      "outputs": [],
      "source": [
        "#%pip install pandas\n",
        "#%pip install numpy\n",
        "#%pip install matplotlib\n",
        "#%pip install seaborn\n",
        "#%pip install -U scikit-learn\n",
        "#%pip install scipy\n",
        "#%pip install xgboost -q\n",
        "\n",
        "# Data Analysis and Visualization Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "#transformação dos dados box -cox\n",
        "from scipy.stats import boxcox\n",
        "\n",
        "# Machine Learning Libraries - treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#validação cruzada\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "######modelos######\n",
        "#modelo de regressão logística\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "#modelo de vizinhos mais próximos (kneighbors classifier)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#modelo de floresta aleatória (random forest classifier)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#Gradient Boosting (XGBoost ou LightGBM)\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "#- Support Vector Machine (SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#####ajuste de hiperparâmetros######\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, learning_curve\n",
        "import time\n",
        "import warnings\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import randint, uniform, loguniform\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "####analise final dos modelos######\n",
        "from sklearn.metrics import RocCurveDisplay, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.base import clone\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9614a35",
      "metadata": {
        "id": "f9614a35"
      },
      "outputs": [],
      "source": [
        "#baixando o dataset e carregando no pandas\n",
        "# O dataset é sobre doenças cardíacas e foi baixado do Kaggle\n",
        "url = 'https://github.com/luiscpl/PUC_MVP_MACHINE_LEARNING/blob/main/heart_cleveland_upload.csv?raw=true'\n",
        "response = requests.get(url)\n",
        "decoded_content = response.content.decode('utf-8')\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe8a362",
      "metadata": {
        "id": "dfe8a362"
      },
      "outputs": [],
      "source": [
        "#exibindo as primeiras linhas do dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e4dec27",
      "metadata": {
        "id": "5e4dec27"
      },
      "source": [
        "- Realizando uma análise inicial dos dados do dataset, nenhuma anormalidade foi encontrada;\n",
        "- Algumas variáveis que, de acordo com a definição no dicionário de dados, são categóricas foram excluídas do dataset original. Em seu lugar, foram criadas novas variáveis categóricas com identificação de rótulos (labels), com o objetivo de não influenciar a análise descritiva do conjunto de dados;\n",
        "- A seguir, apresenta-se a rotina de criação das variáveis categóricas com seus respectivos rótulos (labels), bem como a exclusão de algumas variáveis originais que, por sua natureza, não contribuem significativamente para a análise descritiva nem para a construção do modelo preditivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdbae1e4",
      "metadata": {
        "id": "cdbae1e4"
      },
      "outputs": [],
      "source": [
        "###criando variaveis categóricas com labels das variáveis originais\n",
        "\n",
        "##labels da coluna Sex\n",
        "df['sex_label'] = df['sex'].map({1: 'masculino', 0: 'feminino'})\n",
        "df[['sex', 'sex_label']].head()\n",
        "\n",
        "# Cria os labels para a coluna 'cp'\n",
        "cp_labels = {\n",
        "    0: \"angina típica (dor no peito tipica)\",\n",
        "    1: \"angina atípica (dor no peito, não relacionada ao coração)\",\n",
        "    2: \"dor não anginosa (espasmos, não relacionados ao coração)\",\n",
        "    3: \"assintomático (dor toraxica, sem sinais da doença)\"\n",
        "}\n",
        "\n",
        "df['cp_label'] = df['cp'].map(cp_labels)\n",
        "df[['cp', 'cp_label']].head()\n",
        "\n",
        "\n",
        "# Cria a coluna de labels para a variável 'fbs'\n",
        "df['fbs_label'] = df['fbs'].map({1: 'verdadeiro', 0: 'falso'})\n",
        "df[['fbs', 'fbs_label']].head()\n",
        "\n",
        "# Cria a coluna de labels para a variável 'restecg'\n",
        "restecg_labels = {\n",
        "    0: \"normal\",\n",
        "    1: \"com anormalidade da onda ST-T (inversões da onda T e/ou supradesnivelamento ou infradesnivelamento do segmento ST > 0,05 mV)\",\n",
        "    2: \"apresentando hipertrofia ventricular esquerda provável ou definitiva pelos critérios de Estes\"\n",
        "}\n",
        "\n",
        "df['restecg_label'] = df['restecg'].map(restecg_labels)\n",
        "df[['restecg', 'restecg_label']].head()\n",
        "\n",
        "\n",
        "\n",
        "# Cria a coluna de labels para a variável 'exang'\n",
        "df['exang_label'] = df['exang'].map({1: 'sim', 0: 'não'})\n",
        "df[['exang', 'exang_label']].head()\n",
        "\n",
        "\n",
        "# Cria os labels para a coluna 'slope'\n",
        "slope_labels = {\n",
        "    0: \"ascendente\",\n",
        "    1: \"plano\",\n",
        "    2: \"descida\"\n",
        "}\n",
        "\n",
        "df['slope_label'] = df['slope'].map(slope_labels)\n",
        "df[['slope', 'slope_label']].head()\n",
        "\n",
        "\n",
        "\n",
        "# Cria os labels para a coluna 'thal'\n",
        "thal_labels = {\n",
        "    0: \"normal\",\n",
        "    1: \"defeito corrigido\",\n",
        "    2: \"defeito reversível\"\n",
        "}\n",
        "\n",
        "df['thal_label'] = df['thal'].map(thal_labels)\n",
        "df[['thal', 'thal_label']].head()\n",
        "\n",
        "\n",
        "\n",
        "# Cria os labels para a coluna 'condition'\n",
        "condition_labels = {0: 'sem doença', 1: 'doença'}\n",
        "df['condition_label'] = df['condition'].map(condition_labels)\n",
        "df[['condition', 'condition_label']].head()\n",
        "\n",
        "\n",
        "####excluindo as colunas originais\n",
        "df = df.drop(columns=['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal', 'condition'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6a64616",
      "metadata": {
        "id": "a6a64616"
      },
      "source": [
        "### 2.2 Estatística Descritivas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ed4db17",
      "metadata": {
        "id": "8ed4db17"
      },
      "outputs": [],
      "source": [
        "# dimensão do dataset\n",
        "print(\"dimensão do dataset:\", df.shape)\n",
        "\n",
        "# Informações sobre tipos de dados e valores ausentes\n",
        "df.info()\n",
        "print(\"-\" * 40)\n",
        "# Resumo estatístico de variáveis ​​numéricas\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b5b220a",
      "metadata": {
        "id": "7b5b220a"
      },
      "source": [
        "*Tabela 1: Estatísticas Descritivas*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce675083",
      "metadata": {
        "id": "ce675083"
      },
      "source": [
        "Principais pontos da análise descritiva:\n",
        "- Nenhuma variável do dataset analisado apresenta valores ausentes (missing ou NAs);\n",
        "- O dataset Disease Cleveland UCI contém 297 observações, com seis variáveis numéricas inteiras, uma variável numérica do tipo float e oito variáveis categóricas;\n",
        "- A idade média (variável age) dos indivíduos é de 54,5 anos, com a maioria concentrada na faixa entre 48 e 61 anos;\n",
        "- A pressão arterial de repouso (trestbps) apresenta valores típicos entre 120 e 140 bps, porém com registros extremos chegando a 200 bps — podendo indicar a presença de outliers;\n",
        "- Tanto a idade quanto a pressão arterial apresentam baixa dispersão, com desvios relativamente pequenos;\n",
        "- O colesterol total (chol) possui ampla variabilidade, variando de 126 a 564 mg/dl, com mediana de 243 mg/dl — sugerindo valores potencialmente elevados, como o 564 mg/dl, que pode ser um outlier;\n",
        "- A variável oldpeak, que mede o grau de depressão induzida pelo exercicio físico, apresenta distribuição assimétrica: média de 1,06 e valor máximo de 6,2 — este último, possivelmente um outliers;\n",
        "- A variável ca, possivelmente indicando o número de vasos principais, tem distribuição concentrada em valores baixos, com mediana em 0. O valor máximo (3) também pode ser considerado um outliers.\n",
        "\n",
        "Para uma avaliação mais precisa desses valores atípicos (Outliers), valores extremos e da distribuição, tendência central e dispersão das variáveis clínicas, será realizada uma análise visual por meio de boxplots.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d58fb19",
      "metadata": {
        "id": "9d58fb19"
      },
      "source": [
        "### 2.3 Análise Gráfica"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2beea328",
      "metadata": {
        "id": "2beea328"
      },
      "source": [
        "##### 2.3.1 Boxplot das características clínicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de42673",
      "metadata": {
        "id": "6de42673"
      },
      "outputs": [],
      "source": [
        "# Seleciona apenas as variáveis numéricas do DataFrame\n",
        "numericas = df.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "# Cria um boxplot separado para cada variável numérica\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(numericas.columns):\n",
        "    sns.boxplot(y=numericas[col], ax=axes[i], color='green')\n",
        "    axes[i].set_title(f'Boxplot de {col}', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3507c11c",
      "metadata": {
        "id": "3507c11c"
      },
      "source": [
        "*Gráfico 1 - Boxplot das condições clínicas*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8efec18f",
      "metadata": {
        "id": "8efec18f"
      },
      "source": [
        "Ao analizar o gráfico 1 dos boxplot das características clínicas, pode-se concluir:\n",
        "- A variável age apresenta distribuição aproximadamente simétrica, sem ocorrência de valores atípicos (outliers), indicando uma dispersão equilibrada dos dados em torno da mediana;\n",
        "- As variáveis trestbps, chol, thalach, oldpeak e ca revelam distribuições assimétricas das informações nas figuras. Além disso, nota-se a presença de valores atípicos (Outliers), o que pode indicar variabilidade elevada ou possíveis anomalias nas observações;\n",
        "- Com base na Tabela 1, verifica-se, pelos boxplots, que a variável thalach possui outliers nos limites inferiores, enquanto as variáveis trestbps, chol, oldpeak e ca apresentam outliers nos limites superiores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b47cb8e5",
      "metadata": {
        "id": "b47cb8e5"
      },
      "source": [
        "##### 2.3.2 Proporção de pessoas pela condição cardíaca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d863b5cd",
      "metadata": {
        "id": "d863b5cd"
      },
      "outputs": [],
      "source": [
        "# Conta os valores da coluna 'condition_label' e adiciona o total\n",
        "contagem = df[\"condition_label\"].value_counts()\n",
        "contagem['Total'] = contagem.sum()\n",
        "print(contagem)\n",
        "\n",
        "print(\"-\" * 40)\n",
        "###calculando a propoção de cada condição cardíaca\n",
        "(df[\"condition_label\"].value_counts(normalize=True) * 100).map(\"{:.2f}%\".format)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd07e966",
      "metadata": {
        "id": "cd07e966"
      },
      "source": [
        "*Tabela 2:  Condição Cardíaca dos pacientes*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147fd7ad",
      "metadata": {
        "id": "147fd7ad"
      },
      "outputs": [],
      "source": [
        "# Gráfico de colunas mostrando a proporção (%) de cada condição cardíaca com eixo y de 0 a 100%\n",
        "proporcao = df['condition_label'].value_counts(normalize=True).sort_index() * 100\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = proporcao.plot(\n",
        "    kind='bar',\n",
        "    color=['#8B0000', 'green']\n",
        ")\n",
        "ax.set_xticklabels(['Doença', 'Sem doença'], rotation=0)\n",
        "ax.set_xlabel('Condição Cardíaca', fontweight='bold')\n",
        "ax.set_ylabel('Proporção (%)', fontweight='bold')\n",
        "ax.set_title('Proporção das Condições Cardíacas dos Pacientes', fontweight='bold')\n",
        "ax.set_ylim(0, 100)\n",
        "\n",
        "# Adiciona os valores percentuais nas barras\n",
        "for i, v in enumerate(proporcao):\n",
        "    ax.text(i, v + 2, f\"{v:.2f}%\", ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7dc5b3b",
      "metadata": {
        "id": "c7dc5b3b"
      },
      "source": [
        "*Gráfico 2: Proporção das informações das Condições Cardíacas dos Pacientes*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a91e45f4",
      "metadata": {
        "id": "a91e45f4"
      },
      "source": [
        "Ao analisar o Tabela 2 com Gráfico 2, pode-se concluir que:\n",
        "\n",
        "- A Tabela 2 revela que o conjunto de dados é composto por 137 pacientes (53,87%) com diagnóstico de doença cardíaca e 160 pacientes (46,13%) sem a condição cardíaca.\n",
        "- Já o Gráfico 2 ilustra de forma visual a distribuição das classes, evidenciando um leve desbalanceamento entre os grupos, com uma proporção ligeiramente maior de indivíduos sem diagnóstico de doença cardíaca."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1603ae82",
      "metadata": {
        "id": "1603ae82"
      },
      "source": [
        "##### 2.3.3 Proporção da Condição Cardíaca por sexo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "557de860",
      "metadata": {
        "id": "557de860"
      },
      "outputs": [],
      "source": [
        "# Tabela cruzada entre sexo e condição cardíaca com totais\n",
        "sexo_condicao_abs = pd.crosstab(df['sex_label'], df['condition_label'], margins=True, margins_name='Total')\n",
        "print(sexo_condicao_abs)\n",
        "print(\"-\" * 40)\n",
        "# Proporção entre sexo (linhas) e condição cardíaca (colunas) com totais, normalizando por coluna\n",
        "sexo_condicao_prop_col = pd.crosstab(df['sex_label'], df['condition_label'], margins=True, margins_name='Total', normalize='index')\n",
        "print((sexo_condicao_prop_col * 100).round(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25a48d52",
      "metadata": {
        "id": "25a48d52"
      },
      "source": [
        "*Tabela3: Proporção de sexo pela condição cardíaca*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff8ba9b5",
      "metadata": {
        "id": "ff8ba9b5"
      },
      "outputs": [],
      "source": [
        "# Gráfico de barras agrupadas: proporção da condição cardíaca por sexo\n",
        "condicao_sexo = pd.crosstab(df['sex_label'], df['condition_label'], normalize='index') * 100\n",
        "\n",
        "ax = condicao_sexo[['sem doença', 'doença']].plot(\n",
        "    kind='bar',\n",
        "    color=['green', '#8B0000'],\n",
        "    figsize=(8, 6)\n",
        ")\n",
        "ax.set_xlabel('Sexo', fontweight='bold')\n",
        "ax.set_ylabel('Proporção (%)', fontweight='bold')\n",
        "ax.set_title('Proporção da condição cardíaca por sexo', fontweight='bold')\n",
        "ax.set_xticklabels(['Feminino', 'Masculino'], rotation=0)\n",
        "ax.set_ylim(0, 100)\n",
        "ax.legend(['Sem doença', 'Doença'])\n",
        "\n",
        "# Adiciona os valores percentuais nas barras\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    if height > 0:\n",
        "        ax.annotate(f'{height:.1f}%', (p.get_x() + p.get_width() / 2, height),\n",
        "                    ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feb2d0a8",
      "metadata": {
        "id": "feb2d0a8"
      },
      "source": [
        "*Gráfico 3: Proporção de sexo pela condição cardíaca*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc75b8c",
      "metadata": {
        "id": "4bc75b8c"
      },
      "source": [
        "Ao analisar o Tabela 3 com a Gráfico 3, pode-se concluir que:\n",
        "\n",
        "- No grupo de pacientes com doença cardíaca, temos cerca de 26,0% pacientes do sexo feminino (25) que salta para 55,7% dos pacientes do sexo masculino (112);\n",
        "- No grupo de pacientes sem doenças cardíaca, temos 74,0% dos pacientes do sexo masculino (89) que decai para 44,3% dos pacientes do sexo feminino (71).  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cacaec17",
      "metadata": {
        "id": "cacaec17"
      },
      "source": [
        "##### 2.3.4 Pressão Arterial em Repouso em função da idade e condição cardíaca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cc7082c",
      "metadata": {
        "id": "7cc7082c"
      },
      "outputs": [],
      "source": [
        "# Gráfico de dispersão: idade (age) vs pressão arterial em repouso (trestbps), colorido por condição cardíaca\n",
        "cores = {'doença': '#8B0000', 'sem doença': 'green'}\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for cond in df['condition_label'].unique():\n",
        "    subset = df[df['condition_label'] == cond]\n",
        "    plt.scatter(\n",
        "        subset['age'],\n",
        "        subset['trestbps'],\n",
        "        color=cores[cond],\n",
        "        label=cond.capitalize(),\n",
        "        alpha=0.7\n",
        "    )\n",
        "\n",
        "plt.xlabel('Idade', fontweight='bold')\n",
        "plt.ylabel('Pressão Arterial em Repouso (trestbps)', fontweight='bold')\n",
        "plt.title('Pressão Arterial em Repouso em função da idade e Condição Cardíaca', fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74ec816f",
      "metadata": {
        "id": "74ec816f"
      },
      "source": [
        "*Gráfico 4: Pressão Arterial em Repouso em função da idade e Condição Cardíaca*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16107816",
      "metadata": {
        "id": "16107816"
      },
      "source": [
        "Análise do Gráfico 4 das pessoas com pressão arterial em repouso:\n",
        "\n",
        "- Pacientes com doença cardíaca (em vermelho) estão distribuídos de forma ampla tanto nas idades quanto nos níveis de pressão arterial em repouso, mas há uma leve concentração entre 50 e 70 anos com pressões acima de 130 bps.\n",
        "- Pacientes sem doença cardíaca (verde) estão igualmente espalhados, mas um número considerável aparece com pressão arterial entre 120–140 bps, especialmente entre 40 e 60 anos.\n",
        "- Identificam-se dois pacientes sem diagnóstico de doença cardíaca com pressão arterial inferior a 100 bps e três pacientes apresentam pressão arterial em repouso entre 180 e 200 bps com diagnóstico de doença cardíaca, estes quais podem ser considerados valores atípicos (outliers).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "460d91d8",
      "metadata": {
        "id": "460d91d8"
      },
      "source": [
        "##### 2.3.5 Doença cardíaca em função da idade e da frequência cardíaca máxima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ffdc360",
      "metadata": {
        "id": "7ffdc360"
      },
      "outputs": [],
      "source": [
        "# Plotando age vs thalach para cada condição cardíaca com cores diferentes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(\n",
        "    df[df['condition_label'] == 'doença']['age'],\n",
        "    df[df['condition_label'] == 'doença']['thalach'],\n",
        "    color='#8B0000', label='Doença', alpha=0.7  # vermelho escuro\n",
        ")\n",
        "plt.scatter(\n",
        "    df[df['condition_label'] == 'sem doença']['age'],\n",
        "    df[df['condition_label'] == 'sem doença']['thalach'],\n",
        "    color='green', label='Sem doença', alpha=0.7  # verde\n",
        ")\n",
        "plt.xlabel('Idade', fontweight='bold')\n",
        "plt.ylabel('Frequência Cardíaca Máxima (thalach)', fontweight='bold')\n",
        "plt.title('Doença cardíaca em função da idade e da frequência cardíaca máxima', fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "082ee3d7",
      "metadata": {
        "id": "082ee3d7"
      },
      "source": [
        "*Gráfico 5: Doença cardíaca em função da idade e da frequência cardíaca máxima*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803f8041",
      "metadata": {
        "id": "803f8041"
      },
      "source": [
        "Análise do Gráfico 5 das pessoas com pressão arterial máxima:\n",
        "- Pacientes com doença cardíaca (vermelho) tendem a estar mais concentrados nas faixas etárias intermediárias a avançadas (acima de 50 anos) e se concentram com frequência cardíaca máxima entre 80 até 180 bps;\n",
        "- Pacientes sem doença cardíaca (verde) se distribuem de maneira mais homogênea entre as faixas etárias, embora também predominem em idades médias.\n",
        "- Indivíduos sem doença cardíaca parecem apresentar, em média, frequência cardíaca máxima mais alta, especialmente entre os mais jovens;\n",
        "- Observam-se alguns pontos isolados em ambos os extremos do gráfico, tanto em termos de idade (entre 60 até 70 anos paciente com doença cardíaca) quanto de frequência cardíaca (abaixo de 30 anos, paciente sem doença cardíaca), que podem representar casos atípicos (Outiliers).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd616778",
      "metadata": {
        "id": "bd616778"
      },
      "source": [
        "##### 2.3.6 Condição Cardíaca em função da idade e do colesterol total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a61d4f",
      "metadata": {
        "id": "50a61d4f"
      },
      "outputs": [],
      "source": [
        "# Gráfico de dispersão: colesterol (chol) vs idade (age), colorido por condição cardíaca\n",
        "plt.figure(figsize=(10, 6))\n",
        "for cond in df['condition_label'].unique():\n",
        "    subset = df[df['condition_label'] == cond]\n",
        "    plt.scatter(\n",
        "        subset['age'],\n",
        "        subset['chol'],\n",
        "        color=cores[cond],\n",
        "        label=cond.capitalize(),\n",
        "        alpha=0.7\n",
        "    )\n",
        "\n",
        "plt.xlabel('Idade', fontweight='bold')\n",
        "plt.ylabel('Colesterol (chol)', fontweight='bold')\n",
        "plt.title('Condição Cardíaca em função da idade e do colesterol total', fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6eb927d",
      "metadata": {
        "id": "c6eb927d"
      },
      "source": [
        "*Gráfico 6: Condição Cardíaca em função da idade e do colesterol total*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8148121",
      "metadata": {
        "id": "c8148121"
      },
      "source": [
        "De acordo com Análise do Gráfico 6, pode-se concluir:\n",
        "\n",
        "- Os níveis de colesterol variam amplamente, concentrando-se entre 200 e 400 mg/dl, com alguns pacientes atingindo valores acima de 400 mg/dl;\n",
        "- Pacientes com doença cardíaca (vermelhos) estão distribuídos por toda a faixa de idade, mas nota-se uma maior concentração em idades entre 50 e 70 anos, muitas vezes com níveis de colesterol acima de 200 mg/dl;\n",
        "- Já os sem a condição (verdes) também estão presentes em todas as faixas etárias, porém tendem a ter valores mais concentrados entre 200 e 300 mg/dl, com alguns casos com colesterol elevado, mas menos frequentes;\n",
        "- Acima da faixa de 500 mg/dl, existe um ponto atípico (Outliers) de paciente com colesterol elevado mas sem doença cardíaca, e mais dois pontos atípicos (Outliers) abaixo de 100 mg/dl de pacientes com e sem doença cardíaca."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "556620fe",
      "metadata": {
        "id": "556620fe"
      },
      "source": [
        "##### 2.3.7 Proporção de condição cardíaca pela dor induzida pelo exercício físico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73a8c1b2",
      "metadata": {
        "id": "73a8c1b2"
      },
      "outputs": [],
      "source": [
        "# Tabela de barras agrupadas: exang_label vs condition_label (valores absolutos)\n",
        "exang_condition = pd.crosstab(df['exang_label'], df['condition_label'])\n",
        "print(\"Tabela de valores absolutos:\")\n",
        "display(exang_condition)\n",
        "print(\"-\" * 40)\n",
        "# Tabela de proporções por linha\n",
        "exang_condition_prop = pd.crosstab(df['exang_label'], df['condition_label'], normalize='index')\n",
        "print(\"\\nTabela de proporções por linha (%):\")\n",
        "display(exang_condition_prop.applymap(lambda x: f\"{x:.2%}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8911832",
      "metadata": {
        "id": "f8911832"
      },
      "source": [
        "*Tabela 4: Distribuição da condição cardíaca pela dor induzida pelo exercício físico*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436e08bb",
      "metadata": {
        "id": "436e08bb"
      },
      "outputs": [],
      "source": [
        "# Gráfico de proporção de barras agrupadas: exang_label vs condition_label com eixo y de 0 a 100%\n",
        "exang_condition_prop = pd.crosstab(df['exang_label'], df['condition_label'], normalize='index') * 100\n",
        "\n",
        "ax = exang_condition_prop[['sem doença', 'doença']].plot(\n",
        "    kind='bar',\n",
        "    color=['green', '#8B0000'],\n",
        "    figsize=(8, 6)\n",
        ")\n",
        "ax.set_xlabel('Dor induzida pelo exercício físico', fontweight='bold')\n",
        "ax.set_ylabel('Proporção (%)', fontweight='bold')\n",
        "ax.set_title('Proporção da condição cardíaca pela dor induzida pelo exercício físico', fontweight='bold')\n",
        "ax.set_ylim(0, 100)\n",
        "ax.legend(['Sem doença', 'Doença'])\n",
        "\n",
        "# Adiciona os valores percentuais nas barras\n",
        "for p in ax.patches:\n",
        "    ax.annotate(\n",
        "        f\"{p.get_height():.2f}%\",\n",
        "        (p.get_x() + p.get_width() / 2, p.get_height()),\n",
        "        ha='center', va='bottom', fontweight='bold'\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01af50f5",
      "metadata": {
        "id": "01af50f5"
      },
      "source": [
        "*Gráfico 7: Distribuição de Condição Cardíaca pela dor induzida pelo exercício físico*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d001228c",
      "metadata": {
        "id": "d001228c"
      },
      "source": [
        "- De acordo com a tabela 4 e o Gráfico 7, os pacientes que não relataram dor induzida pelo exercício físico constituem o maior grupo: 137 (68,5%) sem doença cardíaca e 63 (31,5%) com a doença cardíaca;\n",
        "- Pacientes que relataram dor induzida pelo exercício físico, a maioria apresenta diagnóstico de doença cardíaca: 74 (76,29%) pacientes com a doença cardíaca versus 23 (23,71%) pacientes sem a doença cardíaca."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b84da3ba",
      "metadata": {
        "id": "b84da3ba"
      },
      "source": [
        "##### 2.3.8 Média da condição cardíaca induzida pela depresão ocasionada pelo exercício físico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454b0122",
      "metadata": {
        "id": "454b0122"
      },
      "outputs": [],
      "source": [
        "# Gráfico de barras: média de oldpeak por condição cardíaca com eixo y até 2\n",
        "oldpeak_means = df.groupby('condition_label')['oldpeak'].mean().reindex(['doença', 'sem doença'])\n",
        "\n",
        "ax = oldpeak_means.plot(\n",
        "    kind='bar',\n",
        "    color=[cores['doença'], cores['sem doença']],\n",
        "    figsize=(8, 6)\n",
        ")\n",
        "ax.set_xlabel('Condição Cardíaca', fontweight='bold')\n",
        "ax.set_ylabel('Média de Oldpeak', fontweight='bold')\n",
        "ax.set_title('Média da Condição Cardíaca induzida pela depressão ocasionada pelo exercício físico', fontweight='bold')\n",
        "ax.set_xticklabels(['Doença', 'Sem doença'], rotation=0)\n",
        "ax.set_ylim(0, 2)\n",
        "\n",
        "# Adiciona os valores nas barras\n",
        "for i, v in enumerate(oldpeak_means):\n",
        "    ax.text(i, v + 0.05, f\"{v:.2f}\", ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d644263d",
      "metadata": {
        "id": "d644263d"
      },
      "source": [
        "*Gráfico 8: Média da Condição Cardíaca induzida pela depresão ocasionada pelo exercício físico*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cdb6003",
      "metadata": {
        "id": "1cdb6003"
      },
      "source": [
        "Analisando o Gráfico 8, temos:\n",
        "- Uma diferença marcante nos níveis médios de depressão induzida por exercício físico (Oldpeak) entre indivíduos com e sem doença cardíaca;\n",
        "- Pessoas com doença cardíaca apresentaram uma média de 1,59, significativamente mais alta, e as pessoas sem doença cardíaca tiveram média de 0,60, o que sugere menor alteração na condição cardíaca durante o esforço físico.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "033720d9",
      "metadata": {
        "id": "033720d9"
      },
      "source": [
        "##### 2.3.9 Proporção do tipo de dor torácica pela condição cardíaca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e660636",
      "metadata": {
        "id": "7e660636"
      },
      "outputs": [],
      "source": [
        "# Tabela cruzada entre cp_label e condition_label\n",
        "tabela_cp_condition = pd.crosstab(df['cp_label'], df['condition_label'])\n",
        "tabela_cp_condition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a8ea813",
      "metadata": {
        "id": "2a8ea813"
      },
      "source": [
        "*Tabela 5: Distribuição do tipo de dor torácica pela condição cardíaca*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7603b6d",
      "metadata": {
        "id": "a7603b6d"
      },
      "outputs": [],
      "source": [
        "# Calcula a proporção (%) de cada valor de 'cp_label' por 'condition_label'\n",
        "cp_condition_prop = pd.crosstab(df['cp_label'], df['condition_label'], normalize='index') * 100\n",
        "\n",
        "# Garante a ordem das colunas para o gráfico\n",
        "colunas_ordem = ['doença', 'sem doença'] if 'doença' in cp_condition_prop.columns else cp_condition_prop.columns\n",
        "\n",
        "# Cores para as barras\n",
        "cores = ['#8B0000', 'green']\n",
        "\n",
        "# Plota o gráfico de barras empilhadas horizontal\n",
        "ax = cp_condition_prop[colunas_ordem].plot(\n",
        "    kind='barh',\n",
        "    stacked=True,\n",
        "    color=cores,\n",
        "    figsize=(10, 6)\n",
        ")\n",
        "plt.xlabel('Proporção (%)', fontweight='bold')\n",
        "plt.ylabel('Tipo de Dor Torácica', fontweight='bold')\n",
        "plt.title('Proporção do tipo de dor torácica pela condição cardíaca', fontweight='bold')\n",
        "plt.legend(['Doença', 'Sem doença'])\n",
        "\n",
        "# Adiciona os valores percentuais nas barras\n",
        "for i, (idx, row) in enumerate(cp_condition_prop[colunas_ordem].iterrows()):\n",
        "    left = 0\n",
        "    for j, val in enumerate(row):\n",
        "        if val > 0:\n",
        "            ax.text(left + val / 2, i, f\"{val:.1f}%\", va='center', ha='center', color='white', fontweight='bold')\n",
        "        left += val\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36405125",
      "metadata": {
        "id": "36405125"
      },
      "source": [
        "##### 2.3.10 Distribuição de vasos principais comprometidos por condição cardíaca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d8b1482",
      "metadata": {
        "id": "1d8b1482"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.countplot(data=df, x='ca', hue='condition_label', palette=['green','#8B0000'])\n",
        "plt.xlabel('Número de Vasos Principais (ca)', fontweight='bold')\n",
        "plt.ylabel('Contagem', fontweight='bold')\n",
        "plt.title('Distribuição de vasos principais comprometidos por condição cardíaca', fontweight='bold')\n",
        "plt.legend(title='Condição Cardíaca')\n",
        "\n",
        "# Adiciona os valores nas barras\n",
        "for p in ax.patches:\n",
        "    height = p.get_height()\n",
        "    if height > 0:\n",
        "        ax.annotate(f'{int(height)}', (p.get_x() + p.get_width() / 2, height),\n",
        "                    ha='center', va='bottom', fontweight='bold', color='black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "015bdc28",
      "metadata": {
        "id": "015bdc28"
      },
      "source": [
        "*Gráfico 10: Distribuição de vasos principais comprometidos por condição cardíaca*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "807a37a0",
      "metadata": {
        "id": "807a37a0"
      },
      "outputs": [],
      "source": [
        "# Calcula a proporção (%) de cada valor de 'ca' por 'condition_label'\n",
        "ca_condition_prop = pd.crosstab(df['ca'], df['condition_label'], normalize='index') * 100\n",
        "\n",
        "# Plota o gráfico de barras empilhadas\n",
        "ax = ca_condition_prop[['sem doença', 'doença']].plot(\n",
        "    kind='bar',\n",
        "    stacked=True,\n",
        "    color=['green','#8B0000'],\n",
        "    figsize=(8, 6)\n",
        ")\n",
        "ax.set_xlabel('Número de Vasos Principais (ca)', fontweight='bold')\n",
        "ax.set_ylabel('Proporção (%)', fontweight='bold')\n",
        "ax.set_title('Proporção de vasos principais comprometidos por condição cardíaca*', fontweight='bold')\n",
        "ax.set_ylim(0, 100)\n",
        "ax.legend(['Sem doença', 'Doença'])\n",
        "\n",
        "# Adiciona os valores percentuais nas barras\n",
        "for i, row in enumerate(ca_condition_prop[['sem doença', 'doença']].values):\n",
        "    bottom = 0\n",
        "    for j, val in enumerate(row):\n",
        "        if val > 0:\n",
        "            ax.text(i, bottom + val / 2, f\"{val:.1f}%\", ha='center', va='center', color='white', fontweight='bold')\n",
        "        bottom += val\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3161f9a7",
      "metadata": {
        "id": "3161f9a7"
      },
      "source": [
        "*Gráfico 11: Proporção de vasos principais comprometidos por condição cardíaca*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e48cacb",
      "metadata": {
        "id": "9e48cacb"
      },
      "source": [
        "Analisando o Gráfico 10 e o Gráfico 11, pode-se concluir que:\n",
        "\n",
        "- As pessoas que não tem doença cardíaca, com zero vazos tem maior proporção (129 casos; 74,1%) do que em relação as pessoas com doença cardíaca (45 casos; 25,9%);\n",
        "- A medida que o número de vasos principais comprometidos aumenta (1 até 3 vasos comprometidos), temos um aumento vertiginoso de pessoas com doença cardíaca (de 67,7% (44 casos) com 1 vaso comprometido até 85% (17 casos), em 3 vasos comprometidos) do que em relação as pessoas sem doença cardíaca que decai a proporção (de 32,3% (21 casos) com 1 vaso comprometido até 15,0% (3 casos), em 3 vasos comprometidos), e isso, reforça o comprometimento de muúltiplos vasos comprometidos de pessosas com problemas cardíacos;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9ec9481",
      "metadata": {
        "id": "d9ec9481"
      },
      "source": [
        "##### 2.3.11 Matriz de correlação das condições clínicas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c85c2e",
      "metadata": {
        "id": "e5c85c2e"
      },
      "outputs": [],
      "source": [
        "# Matriz de correlação apenas para variáveis numéricas\n",
        "corr = df.corr(numeric_only=True)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    corr,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=[\"green\", \"lightgreen\", \"#FF6347\", \"red\"],\n",
        "    cbar_kws={'label': 'Correlação'}\n",
        ")\n",
        "plt.title('Matriz de Correlação', fontweight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b948117",
      "metadata": {
        "id": "8b948117"
      },
      "source": [
        "*Gráfico 12: Matriz de Correlação das condições clínicas*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aa50694",
      "metadata": {
        "id": "4aa50694"
      },
      "source": [
        "Analisando o Gráfico 12 referente a matriz de correlação das condições clínicas, têm-se:\n",
        "- Não existe uma correlação forte e fraca entre as variáveis clínicas;\n",
        "\n",
        "*Idade (age)*\n",
        "\n",
        "- Possui uma correlação fraca positiva com número de vasos principais (ca = 0,36) e pressão arterial em repouso (trestbps = 0,29),depressão induzida pelo exercício (Oldpeak = 0,20) e colesterol alto (chol = 0,20);\n",
        "- Correlação fraca negativa com frequência cardíaca máxima (thalach = -0,39);\n",
        "\n",
        "*Pressão arterial em repouso (trestbps)*\n",
        "- Correlaciona fracamente com age (0,29), mas pouco com outros fatores.\n",
        "\n",
        "*Colesterol total (chol)*\n",
        "- Com a variável age (0,20) tem correlação fraca positiva e o restante das condições clínicas tem discretas correlações;\n",
        "\n",
        "*Máxima frequência cardíaca (thalach)*\n",
        "- Fraca correlação negativa com age (-0,39) e oldpeak (-0,35) e ca (-0,27) e o restante das condições clínicas tem discretas correlações;\n",
        "\n",
        "*Depressão induzida pelo exercicio (oldpeak)*\n",
        "- Fraca correlação negativa entre age (0,20) e ca (0,29) e o restante das condições clínicas tem discretas correlações;\n",
        "\n",
        "*Número de vasos principais (ca)*\n",
        "- Fraca correlação positiva age (0,36) e oldpeak (0,29) e negativa thalach (-0,27) e o restante das condições clínicas tem discretas correlações;\n",
        "\n",
        "Com as análises de cada variável:\n",
        "- Variáveis centrais para modelos de predição de doença cardíaca são: *age, thalach, oldpeak e ca*;\n",
        "- Variável age se correlaciona com todas as outras variáveis clínicas;\n",
        "- As variáveis *chol e trestbps* possuem correlações menos brandas, então podem ter pouca preditivade com as outras variáveis clínicas com menos iteraçoes.\n",
        "\n",
        "*O próximo passo é realizar o processo de limpeza para a etapa de pré-processamento de dados.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f72993fe",
      "metadata": {
        "id": "f72993fe"
      },
      "source": [
        "# 3. Pré-Processamento de Dados e Preparação dos Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa9ce860",
      "metadata": {
        "id": "aa9ce860"
      },
      "source": [
        "- Nesta etapa, realizaremos a limpeza e a organização do dataset antes da modelagem. Essa fase é essencial para o desenvolvimento de modelos preditivos confiáveis.\n",
        "- Como o conjunto de dados Heart Disease Cleveland UCI não apresenta valores ausentes, não foi necessário aplicar técnicas de imputação de missing values.\n",
        "- Mesmo assim, confirmaremos por meio de análise descritiva se existem valores nulos ou inconsistências que demandem tratamento.\n",
        "- Por fim, dividiremos o dataset em conjuntos de treino e teste, avaliaremos a aplicação de validação cruzada e, em seguida, aplicaremos o tratamento de outliers (tratamento dos dados) para que valores extremos não comprometam as inferências do modelo na próxima etapa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3644a9bc",
      "metadata": {
        "id": "3644a9bc"
      },
      "source": [
        "##### 3.1 Tratamento de valores nulos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d5e819c",
      "metadata": {
        "id": "9d5e819c"
      },
      "source": [
        "Nesta etapa, iremos verificar, se as condições clínica do dataset Heart Disease Cleveland UCI possui valores nulos, pois é importante na definição de exclusão de linhas, e influi no preenchimento média/mediana/moda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1930b0a",
      "metadata": {
        "id": "d1930b0a"
      },
      "outputs": [],
      "source": [
        "# Verificar a presença de valores nulos no dataset original\n",
        "print(\"Valores nulos no dataset Iris:\")\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fbd7a8c",
      "metadata": {
        "id": "9fbd7a8c"
      },
      "source": [
        "*Tabela 6: Valores nulos das condições clínicas*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eecc6b72",
      "metadata": {
        "id": "eecc6b72"
      },
      "source": [
        "De acordo com a tabela 6, o dataset Heart Disease Cleveland UCI não possui valores nulos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d828220",
      "metadata": {
        "id": "6d828220"
      },
      "source": [
        "##### 3.2 Treino e Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c4cdd4",
      "metadata": {
        "id": "83c4cdd4"
      },
      "outputs": [],
      "source": [
        "###criando variaveis categóricas com labels das variáveis originais\n",
        "\n",
        "# Cria os labels para a coluna 'condition'\n",
        "condition = {\n",
        "    \"doença\" :1,\n",
        "    \"sem doença\" : 0,\n",
        "\n",
        "}\n",
        "\n",
        "df['condition'] = df['condition_label'].map(condition)\n",
        "df[['condition', 'condition_label']].head()\n",
        "\n",
        "##labels da coluna Sex\n",
        "sex = {\n",
        "    \"masculino\" :1,\n",
        "    \"feminino\" : 0,\n",
        "\n",
        "}\n",
        "\n",
        "df['sex'] = df['sex_label'].map(sex)\n",
        "df[['sex', 'sex_label']].head()\n",
        "\n",
        "# Cria os labels para a coluna 'cp'\n",
        "cp = {\n",
        "    \"angina típica (dor no peito tipica)\" :0,\n",
        "    \"angina atípica (dor no peito, não relacionada ao coração)\" : 1,\n",
        "    \"dor não anginosa (espasmos, não relacionados ao coração)\" : 2,\n",
        "    \"assintomático (dor toraxica, sem sinais da doença)\" :3\n",
        "}\n",
        "\n",
        "df['cp'] = df['cp_label'].map(cp)\n",
        "df[['cp', 'cp_label']].head()\n",
        "\n",
        "\n",
        "# Cria a coluna de labels para a variável 'fbs'\n",
        "df['fbs'] = df['fbs_label'].map({'verdadeiro' :0, 'falso' :1})\n",
        "df[['fbs', 'fbs_label']].head()\n",
        "\n",
        "\n",
        "# Cria a coluna de labels para a variável 'restecg'\n",
        "restecg = {\n",
        "    \"normal\" :0,\n",
        "    \"com anormalidade da onda ST-T (inversões da onda T e/ou supradesnivelamento ou infradesnivelamento do segmento ST > 0,05 mV)\" :1,\n",
        "    \"apresentando hipertrofia ventricular esquerda provável ou definitiva pelos critérios de Estes\" :2\n",
        "}\n",
        "\n",
        "df['restecg'] = df['restecg_label'].map(restecg)\n",
        "df[['restecg', 'restecg_label']].head()\n",
        "\n",
        "\n",
        "# Cria a coluna de labels para a variável 'exang'\n",
        "df['exang'] = df['exang_label'].map({'sim' :1, 'não' :0})\n",
        "df[['exang', 'exang_label']].head()\n",
        "\n",
        "\n",
        "# Cria os labels para a coluna 'slope'\n",
        "slope = {\n",
        "    \"ascendente\" :0,\n",
        "    \"plano\"      :1,\n",
        "    \"descida\"    :2\n",
        "}\n",
        "\n",
        "df['slope'] = df['slope_label'].map(slope)\n",
        "df[['slope', 'slope_label']].head()\n",
        "\n",
        "\n",
        "# Cria os labels para a coluna 'thal'\n",
        "thal = {\n",
        "    \"normal\"              :0,\n",
        "    \"defeito corrigido\"   :1,\n",
        "    \"defeito reversível\"  :2\n",
        "}\n",
        "\n",
        "df['thal'] = df['thal_label'].map(thal)\n",
        "df[['thal', 'thal_label']].head()\n",
        "\n",
        "\n",
        "\n",
        "####excluindo as colunas originais\n",
        "df = df.drop(columns=[ 'sex_label','cp_label', 'fbs_label', 'restecg_label', 'exang_label', 'slope_label', 'thal_label', 'condition_label'])\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2336ce13",
      "metadata": {
        "id": "2336ce13"
      },
      "source": [
        "- **obs: Como os modelos de machine learning como regressão logística, árvores de decisão, SVM, etc., geralmente não conseguem lidar com strings diretamente. Eles esperam que todas as variáveis de entrada (X_train, X_test) sejam numéricas. Então, antes de realizar o Treino e Teste referente ao dataset Heart Disease Cleveland UCI, foi necessário converter as variáveis categóricas em numéricas**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ae2ec7e",
      "metadata": {
        "id": "4ae2ec7e"
      },
      "outputs": [],
      "source": [
        "# Separar features (X) e target (y)\n",
        "X = df.drop('condition', axis=1)\n",
        "y = df['condition']\n",
        "\n",
        "# Dividir em treino (80%) e teste (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe3f3e1",
      "metadata": {
        "id": "2fe3f3e1"
      },
      "source": [
        "**Análise do Resultado de Treino e Teste do dataset Heart Disease Cleveland da UCI**\n",
        "\n",
        "- A variável condition_label é o alvo (presença ou ausência de doença cardíaca).\n",
        "- A estratificação garante que a proporção de classes seja mantida em treino e teste\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c777462e",
      "metadata": {
        "id": "c777462e"
      },
      "source": [
        "##### 3.2 Método de Validação cruzada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c31c862",
      "metadata": {
        "id": "1c31c862"
      },
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67a30b6d",
      "metadata": {
        "id": "67a30b6d"
      },
      "source": [
        "- Será utilizado o método de validação cruzada, pois o dataset Heart Disease Cleveland da UCI, possui uma amostra de 297 observações, tamanho moderado, com o objetivo de reduzir o risco de overfitting.\n",
        "- A validação cruzada (como K-Fold) ajuda a garantir que o modelo seja avaliado de forma mais robusta, usando diferentes divisões dos dados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d1e934",
      "metadata": {
        "id": "f2d1e934"
      },
      "source": [
        "##### 3.3 Transformação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c009e071",
      "metadata": {
        "id": "c009e071"
      },
      "source": [
        "\n",
        "Abaixo será feito o tratamento dos dados observados nas variáveis clínicas. Para esse tratamento, foi feito:\n",
        "\n",
        "- Normalização pela Média;\n",
        "- Normalização pela Mediana;\n",
        "- Transformação de Box-Cox;\n",
        "- Remoção de Outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "180aba22",
      "metadata": {
        "id": "180aba22"
      },
      "outputs": [],
      "source": [
        "###### tipos de tratamento para Outliers\n",
        "\n",
        "# Selecionando apenas colunas numéricas das variaveis clinicas para as transformações\n",
        "numeric_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']\n",
        "\n",
        "#normalização pela media\n",
        "df_mean = X_train[numeric_cols].apply(lambda x: (x - x.mean()) / x.std())\n",
        "\n",
        "#normalização pela mediana\n",
        "df_median = X_train[numeric_cols].apply(lambda x: (x - x.median()) / x.std())\n",
        "\n",
        "#Transformação box-cox\n",
        "df_boxcox = pd.DataFrame()\n",
        "\n",
        "for col in numeric_cols:\n",
        "    # Evita valores zero ou negativos\n",
        "    data = X_train[col].copy()\n",
        "    if (data <= 0).any():\n",
        "        data = data + 1  # Ajusta para evitar zeros\n",
        "    transformed, _ = boxcox(data)\n",
        "    df_boxcox[col] = transformed\n",
        "\n",
        "\n",
        "# Removendo Outliers pelo com base no IQR\n",
        "def remove_outliers_iqr(df, cols):\n",
        "    df_clean = X_train.copy()\n",
        "    for col in cols:\n",
        "        Q1 = df_clean[col].quantile(0.25)\n",
        "        Q3 = df_clean[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        mask = (df_clean[col] >= Q1 - 1.5 * IQR) & (df_clean[col] <= Q3 + 1.5 * IQR)\n",
        "        df_clean = df_clean[mask]\n",
        "    return df_clean\n",
        "\n",
        "df_outlier_free = remove_outliers_iqr(df, numeric_cols)\n",
        "\n",
        "\n",
        "#################################plotando os resultados por boxplot\n",
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Original\n",
        "plt.subplot(2, 3, 1)\n",
        "sns.boxplot(data=X_train[numeric_cols], color='green')\n",
        "plt.title('Original')\n",
        "\n",
        "# Pela média\n",
        "plt.subplot(2, 3, 2)\n",
        "sns.boxplot(data=df_mean, color='green')\n",
        "plt.title('Normalizado pela Média')\n",
        "\n",
        "# Pela mediana\n",
        "plt.subplot(2, 3, 3)\n",
        "sns.boxplot(data=df_median, color='green')\n",
        "plt.title('Normalizado pela Mediana')\n",
        "\n",
        "# Box-Cox\n",
        "plt.subplot(2, 3, 4)\n",
        "sns.boxplot(data=df_boxcox, color='green')\n",
        "plt.title('Transformação Box-Cox')\n",
        "\n",
        "# retirada de outliers\n",
        "plt.subplot(2, 3, 5)\n",
        "sns.boxplot(data=df_outlier_free, color='green' )\n",
        "plt.title('Retirada de Outliers')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "####escolhido (transformação box-cox)\n",
        "plt.figure(figsize=(14, 8))\n",
        "for i, col in enumerate(df_boxcox.columns):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    sns.boxplot(y=df_boxcox[col], color='green')\n",
        "    plt.title(f'{col} (Box-Cox)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94699a90",
      "metadata": {
        "id": "94699a90"
      },
      "source": [
        "*Gráfico 13: Boxplot dos tratamentos de Outliers das condições clínicas*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca116a6",
      "metadata": {
        "id": "5ca116a6"
      },
      "outputs": [],
      "source": [
        "# dimensão do dataset\n",
        "print(\"dimensão do dataset:\", df_boxcox.shape)\n",
        "\n",
        "# Informações sobre tipos de dados e valores ausentes\n",
        "df_boxcox.info()\n",
        "\n",
        "# Resumo estatístico de variáveis ​​numéricas\n",
        "df_boxcox.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6113c63",
      "metadata": {
        "id": "a6113c63"
      },
      "outputs": [],
      "source": [
        "# Calculando o intervalo interquartílico (IQR), limite inferior e limite superior para variáveis numéricas\n",
        "q1 = df_boxcox.select_dtypes(include=['int64', 'float64']).quantile(0.25)\n",
        "q3 = df_boxcox.select_dtypes(include=['int64', 'float64']).quantile(0.75)\n",
        "iqr = q3 - q1\n",
        "limite_inferior = q1 - 1.5 * iqr\n",
        "limite_superior = q3 + 1.5 * iqr\n",
        "\n",
        "print(\"Intervalo Interquartílico (IQR):\")\n",
        "print(iqr)\n",
        "print(\"-\" * 40)\n",
        "print(\"\\nLimite Inferior:\")\n",
        "print(limite_inferior)\n",
        "print(\"-\" * 40)\n",
        "print(\"\\nLimite Superior:\")\n",
        "print(limite_superior)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd43b78",
      "metadata": {
        "id": "8fd43b78"
      },
      "source": [
        "*Tabela 7: Estatísticas Descritivas das condições clínicas sem outliers*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ffd3caf",
      "metadata": {
        "id": "5ffd3caf"
      },
      "source": [
        "Análise dos Boxplots das Transformações das Variáveis Clínicas no Gráfico 13:\n",
        "- *Normalização pela Média/Mediana*: As transformações utilizando a média não foram eficazes na suavização dos efeitos dos outliers. Isso pode ser atribuído à influência significativa dos valores extremos, além de a normalização pela mediana não ter proporcionado melhorias relevantes em relação aos dados originais.\n",
        "- *Remoção de Outliers via ICS*: Embora a técnica tenha conseguido eliminar as observações discrepantes, a amostra foi reduzida de 237 para 206 observações, resultando em perda de informação. Por esse motivo, optou-se por descartar essa abordagem, uma vez que pode impactar negativamente os resultados na etapa de modelagem.\n",
        "- *Transformação Box-Cox*: Essa técnica demonstrou ser a mais eficaz, promovendo uma simetrização das variáveis com distribuições originalmente assimétricas, aproximando-as de uma distribuição normal. Além disso, contribui para a redução dos efeitos dos outliers — embora as variáveis trestbps e chol ainda apresentem algumas observações discrepantes e as variáveis age, thalach, oldpeak e ca estão com os valores sem outliers e distribuição simétrica.\n",
        "- Depois de aplicada a técnica de Box-cox, pela tabela 7, verificamos que a média e a mediana das condições clinicas estão no mesmo alinhamento dos valores;\n",
        "\n",
        "Na próxima etapa, será feita a a técnica de one-not-encoding, para transformar as variáveis categóricas em variáveis numéricas, para que seja possível aplicar os modelos de machine learning e também será feita a separação do dataset em treino e teste, para que seja possível aplicar os modelos de machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a6cd257",
      "metadata": {
        "id": "0a6cd257"
      },
      "source": [
        "# 4. Modelagem e Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c359938",
      "metadata": {
        "id": "8c359938"
      },
      "source": [
        "### 4.1 Definição dos modelos a serem utilizados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd4a5cd",
      "metadata": {
        "id": "edd4a5cd"
      },
      "source": [
        "01. Nesta etapa, serão construídos e avaliados modelos de Machine Learning com o objetivo de identificar o algoritmo mais representativo para os dados clínicos do dataset Heart Disease Cleveland. O propósito central é desenvolver um modelo capaz de prever a presença de doença cardíaca com base em variáveis clínicas dos pacientes;\n",
        "\n",
        "02. Como os dados clínicos do dataset Heart Disease Cleveland é um problema de classificação binária de prever se o paciente tem ou não problemas cardíacos,então, os modelos escolhidos foram:\n",
        "\n",
        "- Logistic Regression: é um modelo estatístico clássico e direto para classificação binária, ideal quando há uma relação linear entre as variáveis;\n",
        "- Random Forest: modelo baseado em múltiplas árvores de decisão, nessas árvores cria vários subconjuntos aleatórios de dados e variáveis, e a decisão final é feita por votação, sendo robusto contra overfitting, lida bem com dados não lineares e variáveis categóricas ou numéricas.\n",
        "- Gradient Boosting (XGBoost ou LightGBM): constrói um conjunto de árvores sequenciais que corrigem erros anteriores, levando a alta acurácia em classificação binária, requer cuidado com overfitting e tuning de hiperparâmetros;\n",
        "- Support Vector Machine (SVM): É ideal para problemas de classificação binária com margens claras entre classes, sendo eficiente em espaços de alta dimensão, funciona bem com dados não linearmente separáveis usando kernels;\n",
        "- K-Nearest Neighbors (KNN): Útil como baseline, mas sensível à escala e à dimensionalidade.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6112a8a",
      "metadata": {
        "id": "b6112a8a"
      },
      "outputs": [],
      "source": [
        "#modelos (pepilines) a serem testados (função para rodar os Pipelinesos e calcular a acurácia de cada um)\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"KNN\": KNeighborsClassifier()\n",
        "\n",
        "}\n",
        "\n",
        "def fit_and_score(models, X_train, y_train, X_test, y_test):\n",
        "    models_scores = {}\n",
        "    for name, models in models.items():\n",
        "        models.fit(X_train, y_train)\n",
        "        models_scores[name] = models.score(X_test, y_test)\n",
        "    return models_scores\n",
        "\n",
        "\n",
        "scores = fit_and_score(models, X_train, y_train, X_test, y_test)\n",
        "for models, acc in scores.items():\n",
        "    print(f\"modelos: {models}\")\n",
        "    print(f\"Acurácia: {acc:.2f}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4aa8a0f",
      "metadata": {
        "id": "f4aa8a0f"
      },
      "source": [
        "*Tabela 8: Acurácia dos modelos KMN, Logistic Regression e Random Forest dados clínicos do dataset Heart Disease Cleveland*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a53313",
      "metadata": {
        "id": "e8a53313"
      },
      "source": [
        "- Avaliando a Acurácia dos modelos, de acordo com a tabela 8, pode-se concluir pela que os modelos referentes aos dados clínicos do dataset Heart Disease Cleveland, o modelo KNeighborsClassifier (KMN) possui a pior acurácia de 58%, enquanto modelo Logistic Regression possui a melhor acurácia cerca de 90%"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c71f2b8",
      "metadata": {
        "id": "6c71f2b8"
      },
      "source": [
        "### 4.2 Ajuste de Hiperparâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1963ee1",
      "metadata": {
        "id": "d1963ee1"
      },
      "source": [
        "**def. O hiperparâmetro é um parâmetro externo ao modelo de aprendizado de máquina que controla o processo de treinamento, mas não é aprendido diretamente a partir dos dados. Ele é definido antes do treinamento começar e pode ter um impacto significativo na performance do modelo**\n",
        "\n",
        "- É recomendável fazer ajustes de hiperparâmetros no dataset Heart Disease Cleveland de doenças cardíacas, ele tem um número moderado de variáveis e instâncias, que permite aplicar técnicas de otimização sem cobrecarregar o tempo de processamento;\n",
        "\n",
        "- Abaixo será realizado o Pepiline de ajuste de Hiperparâmetros com objetivo de melhorar a performance dos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1bf6a21",
      "metadata": {
        "id": "d1bf6a21"
      },
      "outputs": [],
      "source": [
        "# Hiperparâmetros: GridSearchCV vs RandomizedSearchCV + Learning Curves lado a lado\n",
        "\n",
        "\n",
        "# Definição dos modelos e espaços de busca\n",
        "estimators = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"est\": LogisticRegression(solver='liblinear', max_iter=1000, random_state=42),\n",
        "        \"grid\": {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\"]},\n",
        "        \"rand_dist\": {\"C\": [0.01, 0.1, 1, 10], \"penalty\": [\"l1\", \"l2\"]}\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        \"est\": RandomForestClassifier(random_state=42),\n",
        "        \"grid\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [None, 5, 10], \"max_features\": [\"sqrt\", \"log2\"]},\n",
        "        \"rand_dist\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [None, 5, 10], \"max_features\": [\"sqrt\", \"log2\"]}\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        \"est\": GradientBoostingClassifier(random_state=42),\n",
        "        \"grid\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2], \"max_depth\": [3, 5]},\n",
        "        \"rand_dist\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2], \"max_depth\": [3, 5]}\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        \"est\": SVC(probability=True, random_state=42),\n",
        "        \"grid\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"], \"gamma\": [\"scale\", \"auto\"]},\n",
        "        \"rand_dist\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"], \"gamma\": [\"scale\", \"auto\"]}\n",
        "    },\n",
        "    \"KNN\": {\n",
        "        \"est\": KNeighborsClassifier(),\n",
        "        \"grid\": {\"n_neighbors\": [3, 5, 7, 9], \"weights\": [\"uniform\", \"distance\"]},\n",
        "        \"rand_dist\": {\"n_neighbors\": [3, 5, 7, 9], \"weights\": [\"uniform\", \"distance\"]}\n",
        "    }\n",
        "}\n",
        "\n",
        "results_summary = []\n",
        "\n",
        "# parâmetros comuns às buscas\n",
        "search_kwargs = dict(cv=cv, scoring='accuracy', n_jobs=-1, verbose=0)\n",
        "\n",
        "for name, cfg in estimators.items():\n",
        "    print(f\"\\n{'='*60}\\n{name}\\n{'='*60}\")\n",
        "    est = cfg[\"est\"]\n",
        "    param_grid = cfg[\"grid\"]\n",
        "    param_rand = cfg[\"rand_dist\"]\n",
        "\n",
        "    # GridSearchCV\n",
        "    grid = GridSearchCV(estimator=est, param_grid=param_grid, **search_kwargs)\n",
        "    grid.fit(X_train, y_train)\n",
        "    grid_best = grid.best_estimator_\n",
        "    grid_best_score = grid.best_score_\n",
        "    grid_test_score = grid_best.score(X_test, y_test)\n",
        "\n",
        "    # RandomizedSearchCV (n_iter pequeno para tempo de execução)\n",
        "    rand = RandomizedSearchCV(estimator=est, param_distributions=param_rand, n_iter=10, random_state=42, **search_kwargs)\n",
        "    rand.fit(X_train, y_train)\n",
        "    rand_best = rand.best_estimator_\n",
        "    rand_best_score = rand.best_score_\n",
        "    rand_test_score = rand_best.score(X_test, y_test)\n",
        "\n",
        "    # Armazenar resumo bonito\n",
        "    results_summary.append({\n",
        "        \"model\": name,\n",
        "        \"search\": \"GridSearchCV\",\n",
        "        \"best_cv_score\": round(grid_best_score, 2),\n",
        "        \"test_score\": round(grid_test_score, 2),\n",
        "        \"best_params\": grid.best_params_\n",
        "    })\n",
        "    results_summary.append({\n",
        "        \"model\": name,\n",
        "        \"search\": \"RandomizedSearchCV\",\n",
        "        \"best_cv_score\": round(rand_best_score, 2),\n",
        "        \"test_score\": round(rand_test_score, 2),\n",
        "        \"best_params\": rand.best_params_\n",
        "    })\n",
        "\n",
        "    # Exibir resultados detalhados por modelo\n",
        "    print(\"GridSearchCV -> best cv score: {:.2f} | test score: {:.2f}\".format(grid_best_score, grid_test_score))\n",
        "    print(\"GridSearchCV -> best params:\", grid.best_params_)\n",
        "    print(\"RandomizedSearchCV -> best cv score: {:.2f} | test score: {:.2f}\".format(rand_best_score, rand_test_score))\n",
        "    print(\"RandomizedSearchCV -> best params:\", rand.best_params_)\n",
        "\n",
        "    # Learning Curves para os dois melhores estimadores (Grid x Random)\n",
        "    train_sizes = np.linspace(0.1, 1.0, 5)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    for i, (label, estimator_best) in enumerate([(\"GridSearchCV\", grid_best), (\"RandomizedSearchCV\", rand_best)]):\n",
        "        train_sizes_abs, train_scores, val_scores = learning_curve(\n",
        "            estimator_best, X_train, y_train, cv=cv, train_sizes=train_sizes, scoring='accuracy', n_jobs=-1\n",
        "        )\n",
        "        train_mean = np.mean(train_scores, axis=1)\n",
        "        train_std = np.std(train_scores, axis=1)\n",
        "        val_mean = np.mean(val_scores, axis=1)\n",
        "        val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "        ax = plt.subplot(1, 2, i + 1)\n",
        "        ax.plot(train_sizes_abs, train_mean, 'o-', color='tab:blue', label='Treino')\n",
        "        ax.fill_between(train_sizes_abs, train_mean - train_std, train_mean + train_std, alpha=0.15, color='tab:blue')\n",
        "        ax.plot(train_sizes_abs, val_mean, 'o-', color='tab:orange', label='Validação')\n",
        "        ax.fill_between(train_sizes_abs, val_mean - val_std, val_mean + val_std, alpha=0.15, color='tab:orange')\n",
        "        ax.set_title(f\"{name} ({label})\\ncv_best: {0:.2f}\".format(grid_best_score if label==\"GridSearchCV\" else rand_best_score))\n",
        "        ax.set_xlabel(\"Tamanho do treino\")\n",
        "        ax.set_ylabel(\"Acurácia\")\n",
        "        ax.set_ylim(0.0, 1.05)\n",
        "        ax.grid(True, linestyle='--', alpha=0.3)\n",
        "        ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Exibir resumo consolidado em tabela elegante\n",
        "summary_df = pd.DataFrame(results_summary)\n",
        "# Formatar melhor a coluna de parâmetros como strings curtas\n",
        "summary_df[\"best_params\"] = summary_df[\"best_params\"].apply(lambda p: str(p))\n",
        "summary_df = summary_df[[\"model\", \"search\", \"best_cv_score\", \"test_score\", \"best_params\"]]\n",
        "#print(\"\\nResumo consolidado (valores com 2 casas decimais):\")\n",
        "#display(summary_df.style.hide_index())\n",
        "\n",
        "# Além do resumo, mostrar para cada modelo os hiperparâmetros finais (melhor encontrados)\n",
        "print(\"\\nHiperparâmetros finais por modelo (Grid / Randomized):\")\n",
        "for model in estimators.keys():\n",
        "    g = summary_df[(summary_df.model == model) & (summary_df.search == \"GridSearchCV\")].iloc[0]\n",
        "    r = summary_df[(summary_df.model == model) & (summary_df.search == \"RandomizedSearchCV\")].iloc[0]\n",
        "    print(f\"- {model}:\")\n",
        "    print(f\"    GridSearchCV -> best_cv: {g.best_cv_score:.2f} | test: {g.test_score:.2f} | params: {g.best_params}\")\n",
        "    print(f\"    RandomizedSearchCV -> best_cv: {r.best_cv_score:.2f} | test: {r.test_score:.2f} | params: {r.best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9158506",
      "metadata": {
        "id": "d9158506"
      },
      "source": [
        "*Tabela 9: Pepiline dos hiperparâmetros dos modelos KMN, Logistic Regression e Random Forest dados clínicos do dataset Heart Disease Cleveland*\n",
        "\n",
        "*Grafico 14: learning curves dos hiperparâmetros dos modelos KMN, Logistic Regression e Random Forest dados clínicos do dataset Heart Disease Cleveland*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c784a0",
      "metadata": {
        "id": "10c784a0"
      },
      "source": [
        "Analisando a Tabela 9 e o gráfico 14, temos:\n",
        "\n",
        "1. Utilizou-se as técnicas GridSearchCV e RandomizedSearchCV para explorar a melhor combinação dos modelos com ajustes de hiperparâmetros;\n",
        "2. Foi ajustado os modelos abaixo com os seguintes hiperparâmetros:\n",
        "Hiperparâmetros finais por modelo (Grid / Randomized):\n",
        "- **Logistic Regression:\n",
        "    GridSearchCV -> best_cv: 0.83 | test: 0.90 | params: {'C': 0.1, 'penalty': 'l2'}\n",
        "    RandomizedSearchCV -> best_cv: 0.83 | test: 0.90 | params: {'penalty': 'l2', 'C': 0.1}**\n",
        "- **Random Forest:\n",
        "    GridSearchCV -> best_cv: 0.80 | test: 0.87 | params: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 200}\n",
        "    RandomizedSearchCV -> best_cv: 0.80 | test: 0.87 | params: {'n_estimators': 200, 'max_features': 'log2', 'max_depth': None}**\n",
        "- **Gradient Boosting:\n",
        "    GridSearchCV -> best_cv: 0.78 | test: 0.78 | params: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
        "    RandomizedSearchCV -> best_cv: 0.78 | test: 0.78 | params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.01}**\n",
        "- **SVM:\n",
        "    GridSearchCV -> best_cv: 0.81 | test: 0.90 | params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
        "    RandomizedSearchCV -> best_cv: 0.81 | test: 0.90 | params: {'kernel': 'linear', 'gamma': 'scale', 'C': 1}**\n",
        "- **KNN:\n",
        "    GridSearchCV -> best_cv: 0.68 | test: 0.62 | params: {'n_neighbors': 7, 'weights': 'uniform'}\n",
        "    RandomizedSearchCV -> best_cv: 0.68 | test: 0.62 | params: {'weights': 'uniform', 'n_neighbors': 7}**\n",
        "\n",
        "\n",
        "-> Para Logistic Regression, Random Forest, Gradient Boosting e SVM\n",
        "O CV score (0.83; 0.80; 0.78; 0.81) é menor ou igual ao test score (0.90; 0.87; 0.78; 0.90).\n",
        "Isso indica que não há indício de overfitting — ou seja, o desempenho no teste não é pior que o desempenho médio nos folds de validação.\n",
        "\n",
        "-> Para KNN\n",
        "O CV score (0.68) é maior que o test score (0.62) e são muito baixos\n",
        "Esse gap de 0.06 sugere que o modelo não aprendeu bem aos padrões dos dados, podendo indicar problema de underffiting e um leve problema de overfitting (CV score maior que o test score)\n",
        "\n",
        "3. Analisaremos os gráficos Learning Curve para verificar possíveis problemas de overfitting e underffiting:\n",
        "\n",
        "🔹 Logistic Regression\n",
        "\n",
        "- Treino: ~0.92 → 0.85, Validação: ~0.66 → 0.83\n",
        "- Observação: O gap inicial entre treino e validação é um pouco grande, mas conforme o tamanho do treino aumenta, a validação sobe e se aproxima do treino.\n",
        "- Conclusão: Não há overfitting relevante. Modelo não underffiting, pois ambos convergem em alta acurácia.\n",
        "\n",
        "🔹 Random Forest\n",
        "- Treino: ~1.0 (sempre alto)\n",
        "- Validação: ~0.74 → 0.81\n",
        "- Observação: Treino perfeito → modelo decorou os dados (sinal típico de overfitting no treino). Validação menor, mas melhora com mais dados.\n",
        "\n",
        "Conclusão: Overfitting leve a moderado, mas generalização ainda aceitável. Não há underfitting, pois o modelo tem alta capacidade.\n",
        "\n",
        "🔹 Gradient Boosting\n",
        "\n",
        "- Treino: 1.0 → 0.88\n",
        "- Validação: 0.60 → 0.78\n",
        "- Observação: Gap inicial grande entre treino e validação. Treino diminui, validação aumenta com mais dados.\n",
        "- Conclusão: Gap sugere underfitting inicial, modelo ainda não aprendeu completamente. Pode melhorar aumentando n_estimators ou learning_rate.\n",
        "\n",
        "🔹 SVM (linear)\n",
        "\n",
        "- Treino: ~1.0 → 0.85\n",
        "- Validação: ~0.61 → 0.82\n",
        "- Observação: Treino mais alto que validação → gap visível no início. Conforme aumenta dados, treino e validação se aproximam.\n",
        "- Conclusão: Leve overfitting no início, mas se corrige com mais dados. No fim, generalização boa → não underfit.\n",
        "\n",
        "🔹 KMN\n",
        "\n",
        "- Treino: 0.8 → 0.7\n",
        "- Validação: 0.60 → 0.7\n",
        "- Observação: Gap inicial grande entre treino e validação. Treino diminui, validação aumenta com mais dados.\n",
        "- Conclusão: Gap sugere underfitting inicial, modelo ainda não aprendeu completamente. Pode melhorar aumentando n_estimators ou learning_rate.\n",
        "\n",
        "Pela análise acima, e por possui o melhor CV score, o modelo escolhido será **Logistic Regression com GridSearchCV (GridSearchCV e RandomizedSearchCV possuíram mesmo resultado, escolhido foi GridSearchCV)** para o dataset Heart Disease Cleveland UCI\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66152ee2",
      "metadata": {
        "id": "66152ee2"
      },
      "source": [
        "### 4.4 Método complexo de Modelagem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e54cd7e",
      "metadata": {
        "id": "0e54cd7e"
      },
      "source": [
        "Existem possíveis métodos a serem utilizados para a modelagem dataset Heart Disease Cleveland UCI, abaixo serãom citados alguns:\n",
        "\n",
        "- Calibração de probabilidade (Platt scaling, isotonic) para previsões probabilísticas mais confiáveis em aplicação clínica.\n",
        "- Feature engineering: criação de razões (ex.: colesterol / idade), transformações polinomiais, ou binning clínico; seleção por SHAP/feature importance.\n",
        "- Modelos Bayesianos / Gaussian Processes para incerteza (se desejado).\n",
        "- Redes neurais profundas com embedding para features categóricas (apenas se dataset crescer).\n",
        "- Métodos de tratamento de classe desbalanceada avançados: SMOTE (e variantes), ADASYN, ou ensemble específicos (BalancedRandomForest).\n",
        "- AutoML (H2O AutoML, Auto-Sklearn, AutoGluon) para explorar arquitetura/hiperparâmetros de forma automatizada.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5212bc78",
      "metadata": {
        "id": "5212bc78"
      },
      "source": [
        "### 4.5 Comitê de modelos diferentes para o problema (Ensembles)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4afd152a",
      "metadata": {
        "id": "4afd152a"
      },
      "source": [
        "Recomendo a utilização de Ensembles, geralmente melhoram robustez e performance da modelagem do dataset Heart Disease Cleveland UCI:\n",
        "\n",
        "- Voting classifier (hard ou soft) combinando LR, RandomForest e XGBoost — soft voting com probabilidades costuma ser superior.\n",
        "- Stacking (meta‑learner): base models (RF, XGBoost, SVM) + meta-classifier simples (LogisticRegression) treinado sobre previsões out-of-fold dos base learners; usar CV estratificada para gerar meta‑features.\n",
        "- Blending com holdout se quiser pipeline mais simples.\n",
        "- Modelos distintos capturam diferentes aspectos dos dados (árvores para interações, linear para tendências globais, SVM para fronteiras complexas); combinação reduz viés e variância."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adcf66d9",
      "metadata": {
        "id": "adcf66d9"
      },
      "source": [
        "# 5. Avaliação de Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "352c0ec6",
      "metadata": {
        "id": "352c0ec6"
      },
      "source": [
        "### 5.1 Avaliação do modelo Escolhido"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d10afc6",
      "metadata": {
        "id": "6d10afc6"
      },
      "source": [
        "Neste etapa, o objetivo :\n",
        "- Verificar o desempenho do modelo na aplicação do dataset Heart Disease Cleveland UCI com o objetivo de prever se uma pessoa tem problemas cardíacos ou não;\n",
        "- o modelo escolhido, de acordo com as métricas definidas no cap. 4 modelagem e treinamento seria o modelo **Logistic Regression com GridSearchCV**\n",
        "- Abaixo temos um resumo desse modelo com gráfico Learning Curve:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948cbab1",
      "metadata": {
        "id": "948cbab1"
      },
      "outputs": [],
      "source": [
        "# Filtrar os melhores estimadores da regressão logística\n",
        "logistic_grid = summary_df[(summary_df.model == \"Logistic Regression\") & (summary_df.search == \"GridSearchCV\")].iloc[0]\n",
        "logistic_rand = summary_df[(summary_df.model == \"Logistic Regression\") & (summary_df.search == \"RandomizedSearchCV\")].iloc[0]\n",
        "\n",
        "# Recriar os melhores modelos com os hiperparâmetros encontrados\n",
        "logistic_grid_model = LogisticRegression(**eval(logistic_grid.best_params), solver='liblinear', max_iter=1000, random_state=42)\n",
        "logistic_rand_model = LogisticRegression(**eval(logistic_rand.best_params), solver='liblinear', max_iter=1000, random_state=42)\n",
        "\n",
        "# Curvas de aprendizado\n",
        "train_sizes = np.linspace(0.1, 1.0, 5)\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "for i, (label, model) in enumerate([(\"GridSearchCV\", logistic_grid_model), (\"RandomizedSearchCV\", logistic_rand_model)]):\n",
        "    train_sizes_abs, train_scores, val_scores = learning_curve(\n",
        "        model, X_train, y_train, cv=cv, train_sizes=train_sizes, scoring='accuracy', n_jobs=-1\n",
        "    )\n",
        "    train_mean = np.mean(train_scores, axis=1)\n",
        "    train_std = np.std(train_scores, axis=1)\n",
        "    val_mean = np.mean(val_scores, axis=1)\n",
        "    val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "    ax = plt.subplot(1, 2, i + 1)\n",
        "    ax.plot(train_sizes_abs, train_mean, 'o-', color='tab:blue', label='Treino')\n",
        "    ax.fill_between(train_sizes_abs, train_mean - train_std, train_mean + train_std, alpha=0.15, color='tab:blue')\n",
        "    ax.plot(train_sizes_abs, val_mean, 'o-', color='tab:orange', label='Validação')\n",
        "    ax.fill_between(train_sizes_abs, val_mean - val_std, val_mean + val_std, alpha=0.15, color='tab:orange')\n",
        "    ax.set_title(f\"Regressão Logística ({label})\")\n",
        "    ax.set_xlabel(\"Tamanho do treino\")\n",
        "    ax.set_ylabel(\"Acurácia\")\n",
        "    ax.set_ylim(0.0, 1.05)\n",
        "    ax.grid(True, linestyle='--', alpha=0.3)\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1024d187",
      "metadata": {
        "id": "1024d187"
      },
      "source": [
        "*Grafico 15: learning curve do hiperparâmetro do modelo escolhido escolhido: Logistic Regression dos dados clínicos do dataset Heart Disease Cleveland*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa6654aa",
      "metadata": {
        "id": "aa6654aa"
      },
      "source": [
        "Para a validação da hipótese de prever se uma pessoa tem problemas cardíacos ou não do dataset Heart Disease Cleveland UCI\n",
        "iremos realizar um teste de diagnóstico que:\n",
        "- Compara a taxa de verdadeiro positivos com a taxa de falso positivo de uma pessoa possui problemas cardíacos ou não, ou seja, um falso positivo ocorre quando uma pessoa testa positivo mas na verdade ela nao não tem doença alguma e um falso negativo e quando uma pessoa não tem doença alguma mas na verdade ela esta doente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e418fc",
      "metadata": {
        "id": "14e418fc"
      },
      "outputs": [],
      "source": [
        "# Curvas ROC para o modelo logistico com hiperparâmetros otimizado\n",
        "\n",
        "# Treinar os dois modelos com os melhores parâmetros\n",
        "model_grid = LogisticRegression(**eval(logistic_grid.best_params), solver='liblinear', max_iter=1000, random_state=42)\n",
        "#model_rand = LogisticRegression(**eval(logistic_rand.best_params), solver='liblinear', max_iter=1000, random_state=42)\n",
        "\n",
        "model_grid.fit(X_train, y_train)\n",
        "#model_rand.fit(X_train, y_train)\n",
        "\n",
        "# Obter probabilidades\n",
        "y_proba_grid = model_grid.predict_proba(X_test)[:, 1]\n",
        "#y_proba_rand = model_rand.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Plotar ambas as curvas ROC\n",
        "#plt.figure(figsize=(8, 6))\n",
        "RocCurveDisplay.from_predictions(y_test, y_proba_grid, name=\"GridSearchCV\")\n",
        "#RocCurveDisplay.from_predictions(y_test, y_proba_rand, name=\"RandomizedSearchCV\")\n",
        "plt.title(\"Curvas ROC - Regressão Logística\")\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49950084",
      "metadata": {
        "id": "49950084"
      },
      "source": [
        "*Grafico 16: Curva ROC do hiperparâmetro do modelo Logistic Regression referentes aos dados clínicos do dataset Heart Disease Cleveland*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "240ba605",
      "metadata": {
        "id": "240ba605"
      },
      "source": [
        "Analisando o gráfico 16, temos:\n",
        "- A curva sobe rapidamente para o canto superior esquerdo, o que mostra que o modelo consegue manter uma alta taxa de verdadeiros positivos mesmo com poucos falsos positivos;\n",
        "- AUC = 92%, indica que o modelo está muito bem ajustado, acima de 90% AUC, ou seja, tem uma ótima capacidade de discriminar entre as classes positivas e negativas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bad3e34c",
      "metadata": {
        "id": "bad3e34c"
      },
      "outputs": [],
      "source": [
        "###########matriz de confusão para o modelo logistico otimizado\n",
        "#valores previstos do modelo logistico otimizado\n",
        "y_pred = model_grid.predict(X_test)\n",
        "\n",
        "#matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot da matriz de confusão (usa cm, y_test e y_pred já definidos no notebook)\n",
        "labels = ['Sem doença', 'Doença']\n",
        "\n",
        "# prepara anotações com contagem e porcentagem (sobre o total)\n",
        "total = cm.sum()\n",
        "annot = [[f\"{int(val)}\\n{val/total:.2%}\" for val in row] for row in cm]\n",
        "\n",
        "# usar a paleta solicitada\n",
        "cmap = sns.color_palette(['green', '#8B0000'], as_cmap=True)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "ax = sns.heatmap(\n",
        "    cm,\n",
        "    annot=annot,\n",
        "    fmt='',\n",
        "    cmap=cmap,\n",
        "    xticklabels=labels,\n",
        "    yticklabels=labels,\n",
        "    cbar=True,\n",
        "    annot_kws={'fontsize': 11, 'fontweight': 'bold', 'color': 'white'}\n",
        ")\n",
        "ax.set_xlabel('Predito', fontweight='bold')\n",
        "ax.set_ylabel('Verdadeiro', fontweight='bold')\n",
        "ax.set_title('Matriz de Confusão (contagem e % do total)', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9101554a",
      "metadata": {
        "id": "9101554a"
      },
      "source": [
        "*Grafico 17: Matriz de Confusão dos valores previstos e ajustados do modelo Logistic Regression referentes aos dados clínicos do dataset Heart Disease Cleveland*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5380a39c",
      "metadata": {
        "id": "5380a39c"
      },
      "source": [
        "No gráfico 17, analisando a matriz de confusão têm-se:\n",
        "- 32 pessoas sem doença foram corretamente classificadas, sendo nenhum **falso positivo**, ou seja, o modelo não classificou ninguém saudável como doente\n",
        "- 22 pessoas com doença foram corretamente identificadas, sendo 6 pessoas possuem problemas cardíacos, pois são **falsos negativos**;\n",
        "- Acurácia: (32 + 22) / 60 = 90%\n",
        "- Sensibilidade (Recall para doença): 22 / (22 + 6) = 78.6%\n",
        "- Especificidade (para sem doença): 32 / (32 + 0) = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "325f7ee0",
      "metadata": {
        "id": "325f7ee0"
      },
      "source": [
        "### 5.2 Avaliação das métricas do modelos escolhido"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "266907ad",
      "metadata": {
        "id": "266907ad"
      },
      "source": [
        "Abaixo as seguintes métricas de avaliação dos modelos:\n",
        "\n",
        "- Accuracy: boa para ter uma visão geral.\n",
        "- Precision e Recall: importantes para avaliar falsos positivos/negativos.\n",
        "- F1-Score: equilíbrio entre precisão e recall.\n",
        "- ROC AUC: mede a capacidade de separação entre classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f4fd5fe",
      "metadata": {
        "id": "5f4fd5fe"
      },
      "outputs": [],
      "source": [
        "###########métricas para o modelo logistico otimizado\n",
        "\n",
        "# Predições e probabilidades (usa o modelo já ajustado: model_grid)\n",
        "y_pred = model_grid.predict(X_test)\n",
        "y_proba = model_grid.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Cálculo das métricas\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1v = f1_score(y_test, y_pred, zero_division=0)\n",
        "roc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "# Formatação com duas casas decimais\n",
        "metrics = {\n",
        "    \"Accuracy\": acc,\n",
        "    \"Precision\": prec,\n",
        "    \"Recall\": rec,\n",
        "    \"F1-Score\": f1v,\n",
        "    \"ROC AUC\": roc\n",
        "}\n",
        "metrics_fmt = {k: f\"{v:.2f}\" for k, v in metrics.items()}\n",
        "\n",
        "# Exibe resultados formatados\n",
        "print(\"Métricas do modelo escolhido (Regressão Logística):\")\n",
        "for k, v in metrics_fmt.items():\n",
        "    print(f\"- {k}: {v}\")\n",
        "\n",
        "# Gráfico das métricas com valores embutidos\n",
        "labels = list(metrics.keys())\n",
        "values = [metrics[l] for l in labels]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9, 5))\n",
        "bars = ax.bar(labels, values, color=['#4C72B0', '#55A868', '#C44E52', '#8172B2', '#CCB974'])\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_ylabel(\"Valor\", fontweight='bold')\n",
        "ax.set_title(\"Métricas do Modelo Escolhido (Regressão Logística)\", fontweight='bold')\n",
        "\n",
        "# Anotar os valores nas barras\n",
        "for bar, val in zip(bars, values):\n",
        "    h = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, h + 0.02, f\"{val:.2f}\", ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef2a4813",
      "metadata": {
        "id": "ef2a4813"
      },
      "source": [
        "*Grafico 18: Métricas de Avaliação do modelo Logistic Regression referentes aos dados clínicos do dataset Heart Disease Cleveland*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b4a7f3c",
      "metadata": {
        "id": "4b4a7f3c"
      },
      "source": [
        "Avaliando o gráfico 18, temos:\n",
        "- Acurácia: O modelo acerta 78% das previsões. É uma boa taxa geral, mas pode ser enganosa se houver desbalanceamento entre classes.\n",
        "- Precisão: Indica que o modelo prevêto 74%, tendo um bom controle de falsos positivos.\n",
        "- Recall: O modelo consegue identificar 82% dos casos positivos reais. Excelente para problemas onde é crucial não perder positivos.\n",
        "- F1-SCORE: Equilíbrio entre precisão e recall. Um valor sólido que mostra consistência.\n",
        "- O ROC AUC de 88% é um destaque — mostra que o modelo tem ótima habilidade discriminativa.\n",
        "- O modelo está bem calibrado, com bom equilíbrio entre precisão e recall.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7001aac",
      "metadata": {
        "id": "a7001aac"
      },
      "source": [
        "### 5.3 Avaliação de overfitting do modelo escolhido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3833686f",
      "metadata": {
        "id": "3833686f"
      },
      "outputs": [],
      "source": [
        "# Avaliação de overfitting do modelo escolhido (Logistic Regression otimizado)\n",
        "\n",
        "\n",
        "# Pontuações\n",
        "train_acc = model_grid.score(X_train, y_train)\n",
        "test_acc = model_grid.score(X_test, y_test)\n",
        "\n",
        "cv_scores = cross_val_score(model_grid, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "cv_mean, cv_std = cv_scores.mean(), cv_scores.std()\n",
        "\n",
        "# ROC AUC em treino e teste\n",
        "y_proba_train = model_grid.predict_proba(X_train)[:, 1]\n",
        "y_proba_test = model_grid.predict_proba(X_test)[:, 1]\n",
        "roc_train = roc_auc_score(y_train, y_proba_train)\n",
        "roc_test = roc_auc_score(y_test, y_proba_test)\n",
        "\n",
        "# Gaps para avaliar overfitting/underfitting\n",
        "gap_train_cv = train_acc - cv_mean\n",
        "gap_cv_test = cv_mean - test_acc\n",
        "gap_train_test = train_acc - test_acc\n",
        "\n",
        "print(\"Resumo de desempenho:\")\n",
        "print(f\"- Acurácia (treino): {train_acc:.3f}\")\n",
        "print(f\"- Acurácia (cv {cv.get_n_splits()} folds, média): {cv_mean:.3f} ± {cv_std:.3f}\")\n",
        "print(f\"- Acurácia (teste): {test_acc:.3f}\")\n",
        "print(f\"- Gap Treino - CV: {gap_train_cv:.3f}\")\n",
        "print(f\"- Gap CV - Teste: {gap_cv_test:.3f}\")\n",
        "print(f\"- Gap Treino - Teste: {gap_train_test:.3f}\")\n",
        "print()\n",
        "print(\"ROC AUC:\")\n",
        "print(f\"- ROC AUC (treino): {roc_train:.3f}\")\n",
        "print(f\"- ROC AUC (teste):  {roc_test:.3f}\")\n",
        "\n",
        "# Interpretação simples (impressa)\n",
        "if gap_train_test > 0.1:\n",
        "    print(\"\\nInterpretação: gap Treino-Teste > 0.1 → sinal de overfitting (modelo performa muito melhor no treino).\")\n",
        "elif gap_train_test < -0.05:\n",
        "    print(\"\\nInterpretação: Treino < Teste → possível variação estatística ou underfitting no treino.\")\n",
        "else:\n",
        "    print(\"\\nInterpretação: sem gap grande entre treino e teste → tendência de boa generalização.\")\n",
        "\n",
        "# Curva de aprendizado detalhada para visualização do gap\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    model_grid, X_train, y_train, cv=cv, train_sizes=np.linspace(0.1, 1.0, 7), scoring='accuracy', n_jobs=-1\n",
        ")\n",
        "train_mean = train_scores.mean(axis=1)\n",
        "train_std = train_scores.std(axis=1)\n",
        "val_mean = val_scores.mean(axis=1)\n",
        "val_std = val_scores.std(axis=1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color='tab:blue', label='Treino')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='tab:blue')\n",
        "plt.plot(train_sizes, val_mean, 'o-', color='tab:orange', label='Validação (CV)')\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.15, color='tab:orange')\n",
        "plt.xlabel('Tamanho do conjunto de treino')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.title('Learning Curve — Verificação de Overfitting')\n",
        "plt.ylim(0.4, 1.02)\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "plt.legend()\n",
        "# Anotar gap final\n",
        "final_gap = train_mean[-1] - val_mean[-1]\n",
        "plt.annotate(f'Gap final (Treino - Val): {final_gap:.3f}', xy=(train_sizes[-1], train_mean[-1]), xytext=(train_sizes[-1]*0.6, 0.95),\n",
        "             arrowprops=dict(arrowstyle='->', color='black'), fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"w\"))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b5b08b6",
      "metadata": {
        "id": "0b5b08b6"
      },
      "source": [
        "*Gráfico 19: Learning Curve do modelo Logistic Regression referentes aos dados clínicos do dataset Heart Disease Cleveland*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1989508",
      "metadata": {
        "id": "e1989508"
      },
      "source": [
        "Analisando o gráfico 19, temos:\n",
        "- linha de treino: Acurácia alta desde o início, com leve queda conforme aumenta o conjunto de treino. Isso é esperado, pois modelos treinados com poucos dados tendem a se ajustar melhor ao conjunto pequeno.\n",
        "- Linha de validação: Começa mais baixa, mas sobe gradualmente com o aumento de dados, estabilizando próximo de 78%. Isso indica que o modelo está aprendendo de forma generalizável.\n",
        "- Gap Final (Treino - Validação): O modelo apresenta um pequeno gap, sugerindo leve overfitting, mas nada crítico. O desempenho de validação é sólido e próximo ao de treino.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6372507f",
      "metadata": {
        "id": "6372507f"
      },
      "source": [
        "### 5.2 Desempenho dos modelos gerados em dados não vistos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ccc3c1a",
      "metadata": {
        "id": "4ccc3c1a"
      },
      "outputs": [],
      "source": [
        "# Comparar resultados dos modelos (usa variáveis já presentes no notebook)\n",
        "\n",
        "models_list = summary_df[summary_df['search'] == 'GridSearchCV']['model'].unique()\n",
        "\n",
        "compare_rows = []\n",
        "metrics_by_model = {}\n",
        "\n",
        "for model_name in models_list:\n",
        "    row = summary_df[(summary_df.model == model_name) & (summary_df.search == 'GridSearchCV')].iloc[0]\n",
        "    best_params = eval(row.best_params) if isinstance(row.best_params, str) else row.best_params\n",
        "    base_est = estimators[model_name]['est']\n",
        "    est = clone(base_est).set_params(**best_params)\n",
        "\n",
        "    # Cross‑val (treino) e ajuste final\n",
        "    cv_scores = cross_val_score(est, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    est.fit(X_train, y_train)\n",
        "\n",
        "    # Métricas no conjunto de teste\n",
        "    y_pred = est.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1v = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    # ROC AUC (tenta predict_proba, senão decision_function, senão NaN)\n",
        "    roc = None\n",
        "    try:\n",
        "        if hasattr(est, \"predict_proba\"):\n",
        "            y_proba = est.predict_proba(X_test)[:, 1]\n",
        "            roc = roc_auc_score(y_test, y_proba)\n",
        "        elif hasattr(est, \"decision_function\"):\n",
        "            y_score = est.decision_function(X_test)\n",
        "            roc = roc_auc_score(y_test, y_score)\n",
        "    except Exception:\n",
        "        roc = None\n",
        "\n",
        "    compare_rows.append({\n",
        "        \"model\": model_name,\n",
        "        \"best_cv_mean\": cv_scores.mean(),\n",
        "        \"best_cv_std\": cv_scores.std(),\n",
        "        \"test_accuracy\": acc,\n",
        "        \"test_precision\": prec,\n",
        "        \"test_recall\": rec,\n",
        "        \"test_f1\": f1v,\n",
        "        \"test_roc_auc\": roc,\n",
        "        \"best_params\": best_params\n",
        "    })\n",
        "\n",
        "    metrics_by_model[model_name] = {\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1\": f1v,\n",
        "        \"ROC AUC\": roc if roc is not None else np.nan\n",
        "    }\n",
        "\n",
        "comp_df = pd.DataFrame(compare_rows).set_index('model')\n",
        "display(comp_df)\n",
        "\n",
        "# Mostrar tabela com 2 casas decimais\n",
        "display(comp_df.round(2))\n",
        "\n",
        "\n",
        "# Gráfico: CV mean vs Test accuracy (com valores nas barras, 2 casas decimais)\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "comp_df[['best_cv_mean', 'test_accuracy']].plot(kind='bar', rot=45, ax=ax, colormap='viridis')\n",
        "ax.set_title('Comparação: CV mean vs Test Accuracy')\n",
        "ax.set_ylabel('Acurácia')\n",
        "ax.set_ylim(0, 1)\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
        "\n",
        "# Anotar valores nas barras com 2 casas decimais\n",
        "for p in ax.patches:\n",
        "    h = p.get_height()\n",
        "    if h is None or (isinstance(h, float) and np.isnan(h)):\n",
        "        txt = \"NaN\"\n",
        "    else:\n",
        "        txt = f\"{h:.2f}\"\n",
        "    ax.annotate(txt, (p.get_x() + p.get_width() / 2, h), ha='center', va='bottom',\n",
        "                fontsize=9, fontweight='bold', xytext=(0, 3), textcoords='offset points')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Gráfico: métricas por modelo (Accuracy, Precision, Recall, F1, ROC AUC) com valores (2 casas decimais)\n",
        "metrics_df = pd.DataFrame(metrics_by_model).T\n",
        "metrics_df = metrics_df[[\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC AUC\"]]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "metrics_df.plot(kind='bar', rot=45, ax=ax)\n",
        "ax.set_title('Métricas no Conjunto de Teste por Modelo')\n",
        "ax.set_ylim(0, 1)\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "ax.legend(loc='lower right')\n",
        "ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
        "\n",
        "# Anotar valores em cada barra com 2 casas decimais\n",
        "for p in ax.patches:\n",
        "    h = p.get_height()\n",
        "    if h is None or (isinstance(h, float) and np.isnan(h)):\n",
        "        txt = \"NaN\"\n",
        "    else:\n",
        "        txt = f\"{h:.2f}\"\n",
        "    ax.annotate(txt, (p.get_x() + p.get_width() / 2, h), ha='center', va='bottom',\n",
        "                fontsize=9, fontweight='bold', xytext=(0, 3), textcoords='offset points')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e69d1a1d",
      "metadata": {
        "id": "e69d1a1d"
      },
      "source": [
        "*Gráfico 20: Comparação CV mean vs Test Accuracy e Métricas do conjunto de teste por modelo dos dados clínicos do dataset Heart Disease Cleveland*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9e942a3",
      "metadata": {
        "id": "c9e942a3"
      },
      "source": [
        "Analisando o gráfico 20, temos:\n",
        "\n",
        "-> O gráfico Comparação — CV Mean vs Test Accuracy mostra a acurácia média da validação cruzada (best_cv_mean) e a acurácia no conjunto de teste (test_accuracy) para cinco modelos:\n",
        "- Logistic Regression: CV = 0.87, Test = 0.73\n",
        "- Random Forest: CV = 0.85, Test = 0.70\n",
        "- Gradient Boosting: CV = 0.87, Test = 0.75\n",
        "- SVM: CV = 0.87, Test = 0.85\n",
        "- KNN: CV = 0.85, Test = 0.72\n",
        "- O SVM se destaca com test_accuracy de 0.85, praticamente igual à sua média de validação cruzada — isso indica excelente generalização.\n",
        "- Os demais modelos apresentam uma queda entre validação e teste, sugerindo algum grau de overfitting.\n",
        "\n",
        "-> O gráfico Métricas no Conjunto de Teste por Modelo\n",
        "Este gráfico avalia os cinco modelos usando cinco métricas: Accuracy (acurácia geral), Precision (precisão), Recall (sensibilidade), F1-Score (equilíbrio entre precisão e recall),  ROC AUC (capacidade de discriminar entre classes)\n",
        "\n",
        "- SVM tem os melhores valores em quase todas as métricas, especialmente F1 e Accuracy, além de ROC AUC = 0.84.\n",
        "- Gradient Boosting tem ROC AUC mais baixo (0.78), o que pode indicar menor capacidade de separação entre classes.\n",
        "- Os demais modelos têm desempenho mediano e similar, com ROC AUC em torno de 0.84.\n",
        "\n",
        "-> O modelo SVM se destaca, pois:\n",
        "- Maior test_accuracy (0.85) com consistência em relação à validação.\n",
        "- Excelente desempenho em F1, Precision, Recall e ROC AUC.\n",
        "- Menor diferença entre treino e teste → menos overfitting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}